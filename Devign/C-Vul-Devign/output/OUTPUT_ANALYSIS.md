# Ph√¢n T√≠ch K·∫øt Qu·∫£ Training - BiGRU Vulnerability Detection
## Devign Dataset - C Code Vulnerability Detection

**Ng√†y ph√¢n t√≠ch:** 22/12/2024  
**S·ªë epochs hu·∫•n luy·ªán:** 22  
**Ki·∫øn tr√∫c:** Hybrid BiGRU + V2 Features (Missing Defenses)

---

## üìÅ I. C·∫§U TR√öC TH∆Ø M·ª§C OUTPUT

```
output/
‚îú‚îÄ‚îÄ logs/
‚îÇ   ‚îú‚îÄ‚îÄ training_history.json    # L·ªãch s·ª≠ hu·∫•n luy·ªán (metrics theo epoch)
‚îÇ   ‚îî‚îÄ‚îÄ training_curves.png      # Bi·ªÉu ƒë·ªì hu·∫•n luy·ªán
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ best_model.pt            # Model t·ªët nh·∫•t (best validation)
‚îÇ   ‚îú‚îÄ‚îÄ bigru_vuln_detector_final.pt  # Model cu·ªëi c√πng
‚îÇ   ‚îú‚îÄ‚îÄ swa_model.pt             # Stochastic Weight Averaging model
‚îÇ   ‚îî‚îÄ‚îÄ checkpoint_epoch_*.pt    # 22 checkpoints (epoch 1-22)
‚îî‚îÄ‚îÄ __results___files/
    ‚îî‚îÄ‚îÄ __results___1_71.png     # Visualization t·ª´ notebook
```

---

## üìä II. K·∫æT QU·∫¢ HU·∫§N LUY·ªÜN

### 2.1 Training Metrics (Epoch 22 - Cu·ªëi c√πng)

| Metric | Gi√° tr·ªã |
|--------|---------|
| **Loss** | 0.484 |
| **Accuracy** | 75.3% |
| **Precision** | 78.0% |
| **Recall** | 65.3% |
| **F1-Score** | 71.1% |
| **AUC-ROC** | 83.9% |

### 2.2 Validation Metrics (Best Performance)

| Metric | Epoch 1 | Epoch 14-15 (Best) |
|--------|---------|-------------------|
| **Loss** | 0.590 | ~0.51 |
| **Accuracy** | 68.3% | ~70% |
| **Precision** | 68.2% | ~70% |
| **Recall** | 52.9% | ~60% |
| **F1-Score** | 59.6% | ~70% |
| **AUC-ROC** | 74.9% | ~81.5% |

### 2.3 Ti·∫øn tr√¨nh c·∫£i thi·ªán qua c√°c epochs

| Giai ƒëo·∫°n | Epochs | ƒê·∫∑c ƒëi·ªÉm |
|-----------|--------|----------|
| **Kh·ªüi ƒë·ªông** | 1-5 | Loss gi·∫£m nhanh, F1/AUC tƒÉng m·∫°nh |
| **C·∫£i thi·ªán** | 5-14 | TƒÉng tr∆∞·ªüng ·ªïn ƒë·ªãnh, val metrics c·∫£i thi·ªán ƒë·ªÅu |
| **H·ªôi t·ª•** | 14-22 | Train ti·∫øp t·ª•c c·∫£i thi·ªán, val b·∫Øt ƒë·∫ßu plateau |

---

## üìà III. PH√ÇN T√çCH BI·ªÇU ƒê·ªí HU·∫§N LUY·ªÜN

### 3.1 Loss (H√†m m·∫•t m√°t)
- **Train Loss:** Gi·∫£m ƒë·ªÅu t·ª´ ~0.64 ‚Üí 0.48 sau 22 epochs
- **Val Loss:** Gi·∫£m nhanh 5 epochs ƒë·∫ßu, plateau quanh 0.51 t·ª´ epoch 15
- **Nh·∫≠n x√©t:** Gap gi·ªØa train/val loss b·∫Øt ƒë·∫ßu n·ªõi r·ªông sau epoch 15

### 3.2 F1-Score
- **Train F1:** TƒÉng li√™n t·ª•c t·ª´ 0.58 ‚Üí 0.71
- **Val F1:** Bi·∫øn ƒë·ªông m·∫°nh 10 epochs ƒë·∫ßu, ·ªïn ƒë·ªãnh ~0.70 t·∫°i epoch 14-15
- **Nh·∫≠n x√©t:** ƒê·∫°t peak ~70% tr√™n validation set

### 3.3 AUC-ROC
- **Train AUC:** TƒÉng tr∆∞·ªüng m·∫°nh m·∫Ω, ƒë·∫°t ~0.84 epoch cu·ªëi
- **Val AUC:** TƒÉng nhanh, ƒë·∫°t t·ªëi ∆∞u ~81.5% t·∫°i epoch 14
- **Nh·∫≠n x√©t:** Val AUC ƒëi ngang/gi·∫£m nh·∫π sau epoch 14 trong khi train AUC ti·∫øp t·ª•c tƒÉng

---

## üîç IV. NH·∫¨N X√âT V√Ä ƒê√ÅNH GI√Å

### 4.1 V·ªÅ hi·ªán t∆∞·ª£ng Overfitting
| Kh√≠a c·∫°nh | ƒê√°nh gi√° |
|-----------|----------|
| **M·ª©c ƒë·ªô** | Overfitting **nh·∫π**, xu·∫•t hi·ªán sau epoch 15 |
| **Bi·ªÉu hi·ªán** | Gap Train-Val n·ªõi r·ªông, Val AUC/F1 plateau |
| **Nghi√™m tr·ªçng** | Kh√¥ng qu√° nghi√™m tr·ªçng, gap v·∫´n ·ªü m·ª©c ch·∫•p nh·∫≠n ƒë∆∞·ª£c |

### 4.2 V·ªÅ s·ª± h·ªôi t·ª• (Convergence)
- ‚úÖ M√¥ h√¨nh h·ªôi t·ª• **nhanh** trong 10-12 epochs ƒë·∫ßu
- ‚úÖ Validation metrics ·ªïn ƒë·ªãnh t·ª´ epoch 15
- ‚ö†Ô∏è **Early stopping t·ªëi ∆∞u:** epoch 14-15

### 4.3 So s√°nh v·ªõi m·ª•c ti√™u

| Metric | Hi·ªán t·∫°i | M·ª•c ti√™u | Gap |
|--------|----------|----------|-----|
| **F1-Score** | ~72% | ‚â•75% | **-3%** |
| **AUC-ROC** | ~82% | ‚â•85% | **-3%** |

### 4.4 Nguy√™n nh√¢n Bottleneck

> **K·∫øt lu·∫≠n quan tr·ªçng:** Bottleneck **kh√¥ng n·∫±m ·ªü optimizer/hyperparameter** m√† ·ªü **representation** (c√°ch encode code).

| V·∫•n ƒë·ªÅ | Chi ti·∫øt |
|--------|----------|
| **Single-slice** | Ch·ªâ 1 slice/h√†m, b·ªè qua multi-perspective (forward + backward) |
| **V2 features global** | Kh√¥ng g·∫Øn v·ªõi v·ªã tr√≠ trong sequence, noise t·ª´ to√†n h√†m |
| **Vocab compact** | ~266 tokens, h·∫°n ch·∫ø ph√¢n bi·ªát patterns tinh vi |
| **Kh√¥ng t·∫≠n d·ª•ng ƒë·ªì th·ªã** | AST/CFG/DFG ch·ªâ n√©n th√†nh vector th·ªëng k√™ |

---

## üöÄ V. ƒê·ªÄ XU·∫§T C·∫¢I TI·∫æN (∆ØU TI√äN CAO)

### ∆Øu ti√™n 1: Multi-slice + Slice-level Attention (T√°c ƒë·ªông l·ªõn nh·∫•t)
- T·∫°o nhi·ªÅu slices (backward + forward) thay v√¨ 1 slice
- Th√™m attention qua c√°c slices ƒë·ªÉ b·ªè qua slice nhi·ªÖu
- **K·ª≥ v·ªçng:** +1-2% F1

### ∆Øu ti√™n 2: Token Distance-to-Criterion
- Th√™m positional feature: kho·∫£ng c√°ch token ƒë·∫øn vul_line
- Gi√∫p attention ∆∞u ti√™n tokens g·∫ßn v√πng nghi v·∫•n
- **K·ª≥ v·ªçng:** +0.5-1% F1

### ∆Øu ti√™n 3: V2 Feature Scaling + Localization
- Log-transform cho count/ratio features
- T√≠nh V2 features tr√™n slice thay v√¨ full function
- **K·ª≥ v·ªçng:** +0.5-1% F1/AUC

### ∆Øu ti√™n 4: Cross-validation + Calibration
- K-fold CV ƒë·ªÉ ·ªïn ƒë·ªãnh estimates
- Probability calibration + threshold tuning
- **K·ª≥ v·ªçng:** +1% F1

---

## üìã VI. T·ªîNG K·∫æT

### ƒêi·ªÉm m·∫°nh
- ‚úÖ M√¥ h√¨nh **kh√¥ng overfit n·∫∑ng**, generalization kh√° t·ªët
- ‚úÖ AUC-ROC ƒë·∫°t **>81%**, kh·∫£ nƒÉng ph√¢n bi·ªát class t·ªët
- ‚úÖ H·ªôi t·ª• **nhanh v√† ·ªïn ƒë·ªãnh**
- ‚úÖ C√≥ ƒë·∫ßy ƒë·ªß checkpoints ƒë·ªÉ ph√¢n t√≠ch v√† rollback

### ƒêi·ªÉm c·∫ßn c·∫£i thi·ªán
- ‚ö†Ô∏è F1 plateau ·ªü **~72%**, ch∆∞a ƒë·∫°t target 75%
- ‚ö†Ô∏è Recall th·∫•p (**~60-65%**), b·ªè s√≥t nhi·ªÅu l·ªó h·ªïng
- ‚ö†Ô∏è Representation ch∆∞a ƒë·ªß m·∫°nh ƒë·ªÉ ƒë·∫©y th√™m v√†i ƒëi·ªÉm

### D·ª± b√°o k·∫øt qu·∫£ sau c·∫£i ti·∫øn

| Phase | F1 | AUC-ROC |
|-------|-----|---------|
| **Hi·ªán t·∫°i** | 72% | 82% |
| **Sau Phase 1 (Quick Wins)** | 74-75% | 83-84% |
| **Sau Phase 2 (Structural)** | 76-77% | 85-86% |
| **Sau Phase 3 (Advanced)** | 78-80% | 87-89% |

---

---

## üîß VII. PH√ÇN T√çCH PIPELINE PREPROCESSING

### 7.1 C√°c b∆∞·ªõc x·ª≠ l√Ω d·ªØ li·ªáu (10 b∆∞·ªõc)

```
load ‚Üí vuln_features ‚Üí ast ‚Üí cfg ‚Üí dfg ‚Üí slice ‚Üí tokenize ‚Üí normalize ‚Üí vocab ‚Üí vectorize
```

| B∆∞·ªõc | M√¥ t·∫£ | ƒê·∫ßu ra |
|------|-------|--------|
| **0. load** | Load raw data t·ª´ parquet files | `raw/*.parquet` |
| **1. vuln_features** | Tr√≠ch xu·∫•t V2 features (Missing Defenses) | `vuln_risk_score`, `vuln_risk_level` |
| **2. ast** | Parse AST b·∫±ng tree-sitter | `ast_objects/*.pkl`, `ast_stats` |
| **3. cfg** | Build Control Flow Graph | `cfg_objects/*.pkl`, `cfg_block_count`, `cfg_edge_count` |
| **4. dfg** | Build Data Flow Graph | `dfg_objects/*.pkl`, `dfg_node_count`, `dfg_def_count`, `dfg_use_count` |
| **5. slice** | Code slicing (backward/forward) | `sliced_code`, `slice_lines`, `slice_ratio` |
| **6. tokenize** | Tokenize sliced code | `tokens/*.pkl`, `token_count` |
| **7. normalize** | Normalize (vars, funcs, literals) | `normalized/*.pkl`, `var_count`, `func_count` |
| **8. vocab** | Build vocabulary (t·ª´ train) | `vocab.json`, `vocab_stats.json` |
| **9. vectorize** | Convert tokens ‚Üí integer indices | `vectors/*.npz` (input_ids, attention_mask, labels) |

### 7.2 ƒê√°nh gi√° Pipeline hi·ªán t·∫°i

#### ‚úÖ ƒêi·ªÉm m·∫°nh - ƒê√£ tri·ªÉn khai ƒë·∫ßy ƒë·ªß

| Component | Tr·∫°ng th√°i | Chi ti·∫øt |
|-----------|------------|----------|
| **AST Parsing** | ‚úÖ C√≥ | tree-sitter v·ªõi fallback |
| **CFG Building** | ‚úÖ C√≥ | Control Flow Graph t·ª´ AST |
| **DFG Building** | ‚úÖ C√≥ | Data Flow Graph v·ªõi def-use chains |
| **Backward Slicing** | ‚úÖ C√≥ | CFG/DFG-based, fallback to window |
| **Forward Slicing** | ‚úÖ C√≥ | C√≥ s·∫µn trong `SliceType.FORWARD` |
| **V2 Features** | ‚úÖ C√≥ | 26 features "Missing Defenses" |
| **Checkpointing** | ‚úÖ C√≥ | Resume khi b·ªã interrupt |
| **Memory Management** | ‚úÖ C√≥ | GC sau m·ªói chunk |

#### ‚ö†Ô∏è C√°ch s·ª≠ d·ª•ng CFG/DFG hi·ªán t·∫°i

```python
# kaggle_simple.py: Lines 124-143
slice_config = SliceConfig(
    slice_type=SliceType.BACKWARD,  # ‚Üê S·ª≠ d·ª•ng backward slicing
    window_size=15,                  # ‚Üê Fallback only
    include_control_deps=True,       # ‚Üê C√≥ d√πng CFG
    include_data_deps=True,          # ‚Üê C√≥ d√πng DFG
    max_depth=5,
)
```

#### ‚ö†Ô∏è H·∫°n ch·∫ø hi·ªán t·∫°i

| V·∫•n ƒë·ªÅ | Chi ti·∫øt |
|--------|----------|
| **Single-slice** | Ch·ªâ t·∫°o 1 slice/h√†m, kh√¥ng multi-slice (forward + backward) |
| **CFG/DFG ‚Üí Statistics only** | ƒê·ªì th·ªã ƒë∆∞·ª£c n√©n th√†nh scalar stats, kh√¥ng d√πng GNN |
| **Fallback window** | Khi parse fail ‚Üí d√πng window ¬±15 lines |
| **No slice-level V2** | V2 features t√≠nh tr√™n full function, kh√¥ng tr√™n slice |

---

### 7.2.1 Chi ti·∫øt h·∫°n ch·∫ø 1: Single-Slice

#### V·∫•n ƒë·ªÅ hi·ªán t·∫°i

Pipeline hi·ªán t·∫°i ch·ªâ t·∫°o **1 slice duy nh·∫•t** cho m·ªói h√†m:

```python
# kaggle_simple.py: process_sample()
code_slice = slicer.slice(code, criterion_lines)  # ‚Üê Ch·ªâ 1 slice
sliced_code = code_slice.code
```

#### T·∫°i sao ƒë√¢y l√† h·∫°n ch·∫ø?

| Kh√≠a c·∫°nh | Single-Slice (hi·ªán t·∫°i) | Multi-Slice (ƒë·ªÅ xu·∫•t) |
|-----------|-------------------------|------------------------|
| **G√≥c nh√¨n** | Ch·ªâ backward (nguy√™n nh√¢n) | Backward + Forward (nguy√™n nh√¢n + h·∫≠u qu·∫£) |
| **Noise** | N·∫øu slice ch·ª©a noise, model ph·∫£i h·ªçc b·ªè qua | Attention t·ª± ch·ªçn slice quan tr·ªçng |
| **Context** | Thi·∫øu context v·ªÅ ·∫£nh h∆∞·ªüng c·ªßa bug | Hi·ªÉu ƒë∆∞·ª£c bug lan truy·ªÅn nh∆∞ th·∫ø n√†o |

#### V√≠ d·ª• minh h·ªça

```c
int process_data(char *input) {
    char buffer[64];           // Line 2
    int len = strlen(input);   // Line 3 ‚Üê BACKWARD: len ph·ª• thu·ªôc input
    
    // --- D√≤ng l·ªó h·ªïng ---
    strcpy(buffer, input);     // Line 6 ‚Üê CRITERION (vul_line)
    
    send_to_server(buffer);    // Line 8 ‚Üê FORWARD: buffer b·ªã ·∫£nh h∆∞·ªüng
    log_message(buffer);       // Line 9 ‚Üê FORWARD: buffer b·ªã ·∫£nh h∆∞·ªüng
    return 0;
}
```

**Hi·ªán t·∫°i (Single backward slice t·ª´ line 6):**
```c
char buffer[64];
int len = strlen(input);
strcpy(buffer, input);
```
‚Üí Ch·ªâ th·∫•y nguy√™n nh√¢n, kh√¥ng th·∫•y h·∫≠u qu·∫£

**ƒê·ªÅ xu·∫•t (Multi-slice):**
- **Backward slice**: Lines 2, 3, 6 (nguy√™n nh√¢n)
- **Forward slice**: Lines 6, 8, 9 (h·∫≠u qu·∫£)
- Model c√≥ **2 views** v√† attention quy·∫øt ƒë·ªãnh slice n√†o quan tr·ªçng h∆°n

#### C·∫£i ti·∫øn ƒë·ªÅ xu·∫•t

```python
# Multi-slice approach
slices = []
for vul_line in criterion_lines:
    backward = slicer.backward_slice(code, [vul_line])
    forward = slicer.forward_slice(code, [vul_line])
    slices.extend([backward, forward])

# Slice-level attention trong model
slice_embeddings = [encoder(s) for s in slices]
final_embed = attention_pool(slice_embeddings)  # Model t·ª± ch·ªçn
```

---

### 7.2.2 Chi ti·∫øt h·∫°n ch·∫ø 3: V2 Features Global

#### V·∫•n ƒë·ªÅ hi·ªán t·∫°i

V2 features (Missing Defenses) ƒë∆∞·ª£c t√≠nh tr√™n **to√†n b·ªô h√†m**, kh√¥ng ph·∫£i tr√™n slice:

```python
# kaggle_simple.py: process_sample()
sliced_code = code_slice.code  # ‚Üê Slice ƒë√£ c·∫Øt

# NH∆ØNG: V2 features t√≠nh tr√™n sliced_code (sau slice)
# V·∫§N ƒê·ªÄ: Kh√¥ng c√≥ alignment v·ªõi BiGRU ƒëang nh√¨n
vuln_features = extract_vuln_features_v2(sliced_code, vuln_dict)
```

#### T·∫°i sao ƒë√¢y l√† h·∫°n ch·∫ø?

| V·∫•n ƒë·ªÅ | Gi·∫£i th√≠ch |
|--------|------------|
| **Mismatch context** | BiGRU nh√¨n tokens tu·∫ßn t·ª±, V2 features l√† global stats |
| **Kh√¥ng c√≥ positional info** | V2 kh√¥ng bi·∫øt "missing defense" ·ªü token n√†o |
| **Noise t·ª´ code ngo√†i v√πng quan tr·ªçng** | N·∫øu t√≠nh tr√™n full function, V2 b·ªã pha lo√£ng |

#### V√≠ d·ª• minh h·ªça

```c
void func() {
    // V√πng A: Code an to√†n (50 lines)
    int *p = malloc(sizeof(int));
    if (p == NULL) return;  // ‚Üê C√≥ null check
    *p = 10;
    free(p);
    p = NULL;  // ‚Üê C√≥ defensive coding
    
    // --- V√πng B: D√≤ng l·ªó h·ªïng (10 lines) ---
    char *buf = malloc(100);
    // MISSING: Kh√¥ng c√≥ null check!
    strcpy(buf, user_input);  // ‚Üê Buffer overflow
    // MISSING: Kh√¥ng c√≥ bounds check!
}
```

**V2 Features Global (hi·ªán t·∫°i):**
```
pointer_deref_without_null_check_ratio = 1/2 = 0.5
malloc_without_free_ratio = 1/2 = 0.5
```
‚Üí B·ªã **pha lo√£ng** b·ªüi v√πng A an to√†n!

**V2 Features tr√™n Slice (ƒë·ªÅ xu·∫•t):**
```
# N·∫øu slice ch·ªâ ch·ª©a v√πng B
pointer_deref_without_null_check_ratio = 1/1 = 1.0  ‚Üê R√µ r√†ng h∆°n!
malloc_without_free_ratio = 1/1 = 1.0
```

#### C·∫£i ti·∫øn ƒë·ªÅ xu·∫•t

```python
def extract_v2_features_per_slice(slice_code, original_code, vuln_dict):
    """T√≠nh V2 features tr√™n slice + relative metrics"""
    
    # Features tr√™n slice (v√πng BiGRU ƒëang nh√¨n)
    slice_features = extract_vuln_features_v2(slice_code, vuln_dict)
    
    # Features tr√™n full function (context)
    global_features = extract_vuln_features_v2(original_code, vuln_dict)
    
    return {
        # Slice-level features
        **{f'slice_{k}': v for k, v in slice_features.items()},
        
        # Relative metrics (slice so v·ªõi global)
        'slice_danger_concentration': (
            slice_features['dangerous_call_count'] / 
            max(global_features['dangerous_call_count'], 1)
        ),
        'slice_missing_defense_ratio': (
            slice_features['pointer_deref_without_null_check_count'] /
            max(global_features['pointer_deref_without_null_check_count'], 1)
        ),
    }
```

#### L·ª£i √≠ch

| Metric | Global V2 (hi·ªán t·∫°i) | Slice-level V2 (ƒë·ªÅ xu·∫•t) |
|--------|----------------------|--------------------------|
| **Alignment** | Kh√¥ng kh·ªõp v·ªõi BiGRU context | Kh·ªõp v·ªõi v√πng code model ƒëang x·ª≠ l√Ω |
| **Signal clarity** | B·ªã pha lo√£ng b·ªüi code an to√†n | T·∫≠p trung v√†o v√πng nghi v·∫•n |
| **Interpretability** | Kh√≥ gi·∫£i th√≠ch feature importance | R√µ r√†ng: "slice n√†y c√≥ 100% missing defense" |

### 7.3 Flow x·ª≠ l√Ω chi ti·∫øt (kaggle_simple.py)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Raw Parquet     ‚îÇ
‚îÇ train/val/test  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Extract vul_lines‚îÇ ‚Üê t·ª´ column 'vul_lines'
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ CodeSlicer.slice‚îÇ ‚Üê CFG/DFG-based backward slicing
‚îÇ criterion=      ‚îÇ
‚îÇ   vul_lines     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ extract_vuln_   ‚îÇ
‚îÇ features_v2()   ‚îÇ ‚Üê Tr√≠ch xu·∫•t 26 V2 features
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Tokenize +      ‚îÇ
‚îÇ Normalize       ‚îÇ ‚Üê Regex tokenizer + VAR_x normalization
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Build Vocab     ‚îÇ ‚Üê T·ª´ train set only
‚îÇ (min_freq=2)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Vectorize       ‚îÇ ‚Üê input_ids, attention_mask
‚îÇ (max_len=512)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Output:         ‚îÇ
‚îÇ train.npz       ‚îÇ
‚îÇ train_vuln.npz  ‚îÇ
‚îÇ vocab.json      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 7.4 K·∫øt lu·∫≠n v·ªÅ Pipeline

> **Pipeline ƒë√£ tri·ªÉn khai ƒë·∫ßy ƒë·ªß AST ‚Üí CFG ‚Üí DFG ‚Üí Slicing**
>
> Tuy nhi√™n, c√°ch **t·∫≠n d·ª•ng** c√°c ƒë·ªì th·ªã c√≤n h·∫°n ch·∫ø:
> - CFG/DFG ch·ªâ d√πng ƒë·ªÉ **x√°c ƒë·ªãnh lines cho slicing**
> - Kh√¥ng c√≥ **GNN branch** ƒë·ªÉ h·ªçc tr·ª±c ti·∫øp t·ª´ graph structure
> - V2 features **global** (to√†n h√†m), kh√¥ng localized theo slice

---

*Document generated by Oracle analysis - 22/12/2024*
